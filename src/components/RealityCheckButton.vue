<template>
  <div>
    <div v-if="isLoading" class="spinner-border" role="status">
      <span class="visually-hidden">Loading...</span>
    </div>
    <button
      v-else
      type="button"
      class="btn btn-sm btn-success rounded-pill px-3 py-2 fw-bold"
      @click="makeFetchRequest()"
    >
      Reality Check
    </button>
  </div>
</template>

<script setup lang="ts">
import { storeToRefs } from "pinia";
import { onMounted, ref } from "vue";
import { useUserStore } from "../stores/UserStore";
import { RealityCheckCardData } from "../types/types";

const userStore = useUserStore();
const userStoreRef = storeToRefs(userStore);

const apiKey = userStoreRef.userPrefs.value.password;

const isLoading = ref(false);

const makeFetchRequest = () => {
  isLoading.value = true;
  // get active tab and execute replaceTextElements on it
  chrome.tabs.query({ active: true, currentWindow: true }, function (tabs) {
    if (tabs && tabs.length > 0) {
      const activeTab = tabs[0];
      if (activeTab && activeTab.id) {
        console.log(
          "Sending generate reality check message to tab " + activeTab.id
        );
        chrome.scripting.executeScript({
          target: { tabId: activeTab.id },
          func: generateRealityCheck,
          args: [apiKey],
        });
      } else {
        console.error("Error: Invalid tab object");
      }
    } else {
      console.error("Error: No active tabs found");
    }
  });

  function generateRealityCheck(apiKey: string) {
    // get all text elements (add or remove html tags as needed)
    const allParagraphs = document.querySelectorAll("p, figcaption, li");

    // Test Console Logs
    let paragraphText = "";
    allParagraphs.forEach((paragraph) => {
      const paragraphContent = paragraph?.textContent?.trim();
      if (paragraphContent) {
        paragraphText += paragraphContent + "\n";
      }
    });
    console.log(paragraphText);

    paragraphText = "";

    // filtering out unwanted text
    const paragraphs: Element[] = [];
    // remove all paragraphs that are in a header, footer, or nav element or parent class is navbox
    // Iterate over the selected elements and filter out unwanted ones
    allParagraphs.forEach((paragraph) => {
      const paragraphContent = paragraph?.textContent?.trim();

      // Check if the paragraph is within a <header>, <footer>, or <nav> element or has the class 'navbox'
      // can add more classes or tags to exclude here
      const isInHeaderFooterNavOrHasNavbox =
        paragraph.closest("header, footer, nav") ||
        paragraph.closest(".navbox, .sidebar, .catlinks, .reflist");

      // If the paragraph isn't any of the above, add it to the final paragraphs array
      if (paragraphContent && isInHeaderFooterNavOrHasNavbox) {
        // this is a text element we do not want
      } else if (paragraphContent) {
        paragraphText += paragraphContent + "\n";
        paragraphs.push(paragraph);
      }
    });

    // console.log(paragraphText);

    // just for printing / debug
    paragraphs.forEach((paragraph) => {
      const paragraphContent = paragraph?.textContent?.trim();
      if (paragraphContent) {
        console.log(paragraphContent);
      }
    });

    // variable to store extracted paragraphs and their ids (ids are generated by us based on the order of the paragraphs)
    interface ExtractedParagraph {
      id: string;
      content: string;
    }
    const extractedParagraphs: ExtractedParagraph[] = [];

    // max characters defines upper limit on each group (needed to stay under the openai token limit)
    const maxCharacters = 3000;
    let totalCharacters = 0;

    paragraphs.forEach((paragraph, index) => {
      const paragraphContent = paragraph?.textContent?.trim();
      const paragraphId = index + 1;
      if (paragraphContent) {
        extractedParagraphs.push({
          id: paragraphId.toString(),
          content: paragraphContent || "",
        });
      }
    });

    // at this point, we want to create groups of paragraphs to send to the LLM
    // we need to create groups to stay under the maximum token count
    // we also want to keep paragraphs together, so we can't split them up

    const groupedParagraphs = [];
    let currentGroup: ExtractedParagraph[] = [];
    extractedParagraphs.forEach((paragraph) => {
      const paragraphLength = paragraph.content.length;
      if (totalCharacters + paragraphLength > maxCharacters) {
        groupedParagraphs.push(currentGroup);
        currentGroup = [];
        totalCharacters = 0;
      }
      currentGroup.push(paragraph);
      totalCharacters += paragraphLength;
    });

    // push the last group since it didn't hit the token limit
    groupedParagraphs.push(currentGroup);

    // cap groupedParagraphs at X groups (for testing, uncomment to do entire document)
    // groupedParagraphs.splice(5);

    // send groups to openai in a loop

    const totalGroups: number = groupedParagraphs.length;
    let currentGroupNumber: number = 0;

    const logicalFallacies: string[] = [];
    const biasedStatements: string[] = [];
    const unsupportedArguments: string[] = [];
    const questionsForFurtherExploration: string[] = [];

    console.log("Total groups: " + totalGroups);

    // get page URL
    const url: string = window.location.href;
    // get page title
    const title: string = document.title;
    // get date
    const date: string = new Date().toLocaleDateString();
    // get favicon
    const icon: string =
      "https://preview.redd.it/1ctzmm4jbpg11.jpg?auto=webp&s=196146a0e42e718e87c191dcc2126bda174ba00d";

    groupedParagraphs.forEach((group) => {
      // map elements to string to send to openai
      const extractedParagraphsString = group
        .map((paragraph) => {
          return `${paragraph.content}`;
        })
        .join("\n");

      // console.log("Input:");
      // console.log(extractedParagraphsString);

      // send to openai
      console.log("Sending group to OpenAI");
      const apiUrl = "https://api.openai.com/v1/chat/completions";

      let userPrompt =
        "You are a thought partner helping me think critically about the piece of content that was provided. First, start by flagging logical fallacies, biased statements, and unsupported arguments. Provide 1 - 2 sentence explanation for each logical fallacy, biased statement, and unsupported argument. Then, provide me a list of questions that can help me continue to explore this topic. Please format the question in a way that can be copied and pasted into Google for further exploration. If you did find logical fallacies, biased statements, or unsupported arguments, please write questions that would help me think critically about these issues and lead me to more objective sources. First, provide me an example:";

      let assistantResponse =
        '{\n"Logical Fallacies": [\n    "False Cause Fallacy: The argument that 5G technology caused various health and environmental issues in the town meeting, despite the fact that the company representative clarified that it hadn\'t been turned on yet.",\n    "Hasty Generalization Fallacy: Assuming that 7% of people in the U.S. who think chocolate milk comes from brown cows are dumb or uneducated based on this limited statistic."\n  ],\n"Biased Statements": [\n   "The statement \\"Are they dumb or just uneducated?\\" assumes that the individuals who hold certain beliefs or engage in certain behaviors lack intelligence or knowledge."\n],\n"Unsupported Arguments": [\n   "The article claims that 16.4 million people in the U.S. think chocolate milk comes from brown cows without providing any factual evidence or source to support this claim."\n],\n"Questions for Critical Thinking": [\n    "How can we evaluate the accuracy of the claim that 16.4 million people in the U.S. think chocolate milk comes from brown cows? Is there any reliable data or research to support or refute this claim?"\n]\n}';

      let prompt =
        "That's perfect. Don't forget to backslash the quotation marks. Now do this but for the following content:\n";

      prompt += extractedParagraphsString;

      console.log("Prompt: " + prompt);

      let messages = [
        {
          role: "user",
          content: userPrompt,
        },
        {
          role: "assistant",
          content: assistantResponse,
        },
        {
          role: "user",
          content: prompt,
        },
      ];

      fetch(apiUrl, {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          Authorization: "Bearer " + apiKey,
        },
        body: JSON.stringify({
          model: "gpt-3.5-turbo",
          messages: messages,
          temperature: 0.9,
        }),
      })
        .then((response) => response.json())
        .then((responseData) => {
          //console.log(responseData);
          const response = responseData["choices"][0]["message"]["content"];
          console.log("OpenAI Response:");
          console.log(response);
          if (response) {
            // increment group number here, even though it might not be valid JSON
            // should serve to just ignore invalid JSON whilst still keeping all valid ones
            currentGroupNumber++;
            // try to parse response as JSON
            try {
              const responseJson = JSON.parse(response);
              console.log("JSON Response:");
              console.log(responseJson);
              // if valid JSON, create RealityCheckCardData
              if (true) {
                if (responseJson["Logical Fallacies"].length > 0) {
                  responseJson["Logical Fallacies"].forEach(
                    (fallacy: string) => {
                      // check for "None" or "N/A" and ignore
                      if (
                        fallacy.toLowerCase() !== "none" &&
                        fallacy.toLowerCase() !== "n/a" &&
                        fallacy.toLowerCase() !== "na" &&
                        !fallacy.toLowerCase().startsWith("none")
                      ) {
                        logicalFallacies.push(fallacy);
                      }
                    }
                  );
                }

                if (responseJson["Biased Statements"].length > 0) {
                  responseJson["Biased Statements"].forEach(
                    (statement: string) => {
                      if (
                        statement.toLowerCase() !== "none" &&
                        statement.toLowerCase() !== "n/a" &&
                        statement.toLowerCase() !== "na" &&
                        !statement.toLowerCase().startsWith("none")
                      ) {
                        biasedStatements.push(statement);
                      }
                    }
                  );
                }

                if (responseJson["Unsupported Arguments"].length > 0) {
                  responseJson["Unsupported Arguments"].forEach(
                    (argument: string) => {
                      if (
                        argument.toLowerCase() !== "none" &&
                        argument.toLowerCase() !== "n/a" &&
                        argument.toLowerCase() !== "na" &&
                        !argument.toLowerCase().startsWith("none")
                      ) {
                        unsupportedArguments.push(argument);
                      }
                    }
                  );
                }

                if (
                  responseJson["Questions for Critical Thinking"].length > 0
                ) {
                  responseJson["Questions for Critical Thinking"].forEach(
                    (question: string) => {
                      if (
                        question.toLowerCase() !== "none" &&
                        question.toLowerCase() !== "n/a" &&
                        question.toLowerCase() !== "na" &&
                        !question.toLowerCase().startsWith("none")
                      ) {
                        questionsForFurtherExploration.push(question);
                      }
                    }
                  );
                }

                console.log("Finished parsing group");

                // console.log("Grabbed notecards from group " + currentGroupNumber + " of " + totalGroups + " total groups");
                // check if this was the final group, if so, add to userstore
                if (currentGroupNumber >= totalGroups) {
                  console.log("Creating RealityCheckCardData");

                  const realityCheckCardData: RealityCheckCardData = {
                    title: title,
                    url: url,
                    icon: icon,
                    dateAdded: date,
                    "Logical Fallacies": logicalFallacies,
                    "Biased Statements": biasedStatements,
                    "Unsupported Arguments": unsupportedArguments,
                    "Questions for Further Exploration":
                      questionsForFurtherExploration,
                    dataType: "realitycheck",
                  };

                  console.log(realityCheckCardData);
                  console.log("Sending store message");
                  chrome.runtime.sendMessage({
                    action: "storeRealityCheck",
                    content: realityCheckCardData,
                  });
                }
              }
            } catch (error) {
              console.log(error);
              console.log("Error parsing JSON response");
            }
          }
        })
        .catch((error) => {
          console.log(error);
        });
    });
  }
};

onMounted(() => {
  if (chrome.runtime && chrome.runtime.onMessage) {
    chrome.runtime.onMessage.addListener(function (request) {
      if (request.action === "storeRealityCheck") {
        isLoading.value = false;
        console.log("Received storeRealityCheck message");
        const responseData = request.content as RealityCheckCardData;
        console.log(responseData);
        userStoreRef.realityCheckCardData.value.push(responseData);
      } else {
        isLoading.value = false;
        console.log("Received unknown message");
        console.log(request);
      }
    });
  }
});
</script>

<style scoped></style>
